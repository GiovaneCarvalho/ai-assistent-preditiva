{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f564e9e",
   "metadata": {},
   "source": [
    "Fazendo a primeira chamada da LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed88eeb",
   "metadata": {},
   "source": [
    "Criando nossa primeira chamada de LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9ab058",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd10059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein (1879-1955) foi um físico teórico alemão que desenvolveu a teoria da relatividade, um dos dois pilares da física moderna (o outro é a mecânica quântica).  Sua famosa equação, E=mc², que postula a equivalência entre energia e massa, é uma das equações mais conhecidas do mundo.\\n\\nAlém da relatividade, Einstein fez contribuições significativas em outros campos da física, incluindo a mecânica estatística (explicação do movimento browniano) e a cosmologia (teoria de um universo em expansão).  Ele recebeu o Prêmio Nobel de Física em 1921 por sua explicação do efeito fotoelétrico, que foi crucial para o desenvolvimento da mecânica quântica.\\n\\nEinstein não foi apenas um gênio científico, mas também uma figura pública altamente influente.  Suas ideias revolucionaram a compreensão do universo e sua imagem icônica se tornou sinônimo de inteligência e genialidade.  Ele também foi um pacifista declarado e um defensor do sionismo.  Sua vida e obra continuam a inspirar e a ser objeto de estudo até os dias de hoje.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Quem foi Albert Einstein?\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b8d515",
   "metadata": {},
   "source": [
    "Construindo nossa primeira estrutura de RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977aa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2565c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path().resolve()\n",
    "DOCS_DIR = BASE_DIR / \"docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e36e05",
   "metadata": {},
   "source": [
    "Escolhendo a estrutura de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23dca1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\degio\\AppData\\Local\\Temp\\ipykernel_23520\\323160131.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\degio\\Downloads\\2025\\Preditiva\\Formação AI\\Conteudos\\Módulo 8 - Projetos Finais\\CASE 1\\Assistente_AI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_vectorstore(filepath: str, save_path: str):\n",
    "    loader = PyPDFLoader(DOCS_DIR / filepath)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=500)\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "    vectorstore = FAISS.from_documents(documents, embedding)\n",
    "    vectorstore.save_local(f\"vectorstores/{save_path}\")\n",
    "    retriver = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 7}\n",
    "    )\n",
    "    return retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70d57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_perguntas_frequentes = load_pdf_vectorstore(\n",
    "    \"Perguntas Frequentes.pdf\", \"vectorstore_perguntas_frequentes\"\n",
    ")\n",
    "retriver_manual_tecnico = load_pdf_vectorstore(\n",
    "    \"Manual Tecnico de Produtos.pdf\", \"vectorstore_manual_tecnico_produtos\"\n",
    ")\n",
    "retriver_politicas_procedimentos = load_pdf_vectorstore(\n",
    "    \"Politicas e Procedimentos.pdf\", \"vectorstore_politicas_procedimentos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ec4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_vectorstore(filepath: str, save_path: str):\n",
    "    df = pd.read_excel(DOCS_DIR / filepath)\n",
    "    documents = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = \" \".join([str(cell) for cell in row if pd.notna(cell)])\n",
    "        documents.append(Document(page_content=text, metadata={\"row\": idx}))\n",
    "\n",
    "    vectorstore_tickers = FAISS.from_documents(documents, embedding)\n",
    "    vectorstore_tickers.save_local(\"vectorstores/vectorstore_tickets\")\n",
    "    retriver_tickets = vectorstore_tickers.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 7}\n",
    "    )\n",
    "\n",
    "    return retriver_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5125dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_tickets = load_excel_vectorstore(\"Tickets.xlsx\", \"vectorstore_tickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d86f81",
   "metadata": {},
   "source": [
    "Criando os agentes assistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703ecbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, List\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict, total=False):\n",
    "    query: str\n",
    "    route: Optional[str]\n",
    "    anwser: Optional[str]\n",
    "    chat_history: Optional[List[BaseMessage]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cfa636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_with_retriever(\n",
    "    state: State, papel: str, prompt_instrucoes: str, retriver=None\n",
    "):\n",
    "    query = state[\"query\"]\n",
    "    chat_history = state.get(\"chat_history\", [])\n",
    "    contexto = \"\"\n",
    "\n",
    "    if retriver:\n",
    "        recuperados = retriver.get_relevant_documents(query)\n",
    "        if recuperados:\n",
    "            contexto = \"\\n\".join([d.page_content for d in recuperados])\n",
    "\n",
    "    mensagens = [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                f\"Você é um {papel}. \"\n",
    "                f\"Suas instruções:\\n{prompt_instrucoes}\\n\\n\"\n",
    "                f\"- Use sempre o contexto recuperado para responder à ÚLTIMA pergunta do usuário.\\n\"\n",
    "                f\"- Use o histórico da conversa para entender o contexto geral e perguntas de acompanhamento.\\n\"\n",
    "                f\"- Se não houver informações relevantes no contexto, diga que não encontrou dados suficientes para responder.\\n\"\n",
    "                f\"- Evite inventar informações.\"\n",
    "            )\n",
    "        ),\n",
    "        *chat_history,\n",
    "        HumanMessage(\n",
    "            content=(\n",
    "                f\"Pergunta do usuário:\\n{query}\\n\\n\"\n",
    "                f\"Contexto disponível para esta pergunta:\\n{contexto if contexto else '[Nenhum contexto encontrado]'}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    resposta = llm.invoke(mensagens)\n",
    "    state[\"anwser\"] = resposta.content\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21dcc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_detalhe_tecnico(state: State):\n",
    "    prompt_instrucoes = (\n",
    "        \"Seja um **especialista em suporte técnico e produto**. \"\n",
    "        \"Você deve responder a perguntas sobre **especificações técnicas**, \"\n",
    "        \"**instruções de instalação**, **manutenção preventiva** e **solução de problemas**. \"\n",
    "        \"Sua resposta deve ser precisa, técnica e objetiva, baseada estritamente no manual técnico. \"\n",
    "        \"Para problemas, ofereça uma solução clara e passo a passo.\"\n",
    "    )\n",
    "    return agent_with_retriever(\n",
    "        state,\n",
    "        \"especialista em detalhes técnicos\",\n",
    "        prompt_instrucoes,\n",
    "        retriver_manual_tecnico,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a2a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_perguntas_e_respostas(state: State):\n",
    "    prompt_instrucoes = (\n",
    "        \"Seja um **especialista em Perguntas Frequentes (FAQ)**. \"\n",
    "        \"Sua função é fornecer respostas diretas e concisas a perguntas comuns. \"\n",
    "        \"Responda como se estivesse consultando uma base de conhecimento, mantendo a resposta factual e sem rodeios. \"\n",
    "        \"Se a pergunta se referir a um problema, ofereça a resposta e, se necessário, sugira o contato com o suporte técnico para casos complexos.\"\n",
    "    )\n",
    "    return agent_with_retriever(\n",
    "        state, \"especialista em FAQs\", prompt_instrucoes, retriver_perguntas_frequentes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea5ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_politicas_e_procedimentos(state: State):\n",
    "    prompt_instrucoes = (\n",
    "        \"Seja um **especialista em políticas e procedimentos da empresa**. \"\n",
    "        \"Sua tarefa é responder a perguntas sobre **garantia**, **horário de atendimento**, \"\n",
    "        \"**prazos de SLA** e **regras internas de suporte**. \"\n",
    "        \"Sua resposta deve ser formal e baseada nos documentos oficiais, garantindo que o cliente entenda as regras e os processos da empresa.\"\n",
    "    )\n",
    "    return agent_with_retriever(\n",
    "        state,\n",
    "        \"especialista em políticas e procedimentos\",\n",
    "        prompt_instrucoes,\n",
    "        retriver_politicas_procedimentos,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ef62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_tickets(state: State):\n",
    "    prompt_instrucoes = (\n",
    "        \"Seja um **especialista em tickets de atendimento**. \"\n",
    "        \"Você deve fornecer informações precisas sobre o **status e detalhes de um chamado existente**. \"\n",
    "        \"Sua resposta deve ser direta, baseada nos dados do ticket (Ticket ID, Status, Responsável, Descrição do Problema). \"\n",
    "        \"Se o usuário perguntar sobre um ticket específico, forneça as informações relevantes e mantenha a resposta curta e direta.\"\n",
    "    )\n",
    "    return agent_with_retriever(\n",
    "        state,\n",
    "        \"especialista em tickets de atendimento\",\n",
    "        prompt_instrucoes,\n",
    "        retriver_tickets,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1033613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor(state: State):\n",
    "    query = state[\"query\"]\n",
    "    chat_history = state.get(\"chat_history\", [])\n",
    "\n",
    "    mensagens = [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"Você é um assistente virtual de atendimento ao cliente da **Industech**, uma empresa especializada em produtos industriais.\n",
    "\n",
    "            Sua principal responsabilidade é atuar como um supervisor, **roteando as perguntas dos clientes para o agente especialista mais adequado**.\n",
    "\n",
    "            Sua única função é analisar a pergunta do usuário e retornar **uma palavra-chave** que representa o agente responsável. Se a pergunta não se encaixar em nenhuma categoria de especialista, ou se for uma saudação ou uma pergunta sobre suas próprias capacidades, você deve responder de forma amigável diretamente ao cliente, sem rotear.\n",
    "\n",
    "            A sua resposta deve ser:\n",
    "            - **Uma frase de resposta direta**, caso a pergunta seja geral (ex: \"Olá\", \"Tudo bem?\", \"O que você faz?\").\n",
    "            - **Uma das seguintes palavras-chave**, em minúsculas e sem pontuação, para roteamento:\n",
    "            - **detalhe_tecnico**: para perguntas sobre **especificações técnicas**, **manuais de produtos** ou **solução de problemas**.\n",
    "            - **perguntas_e_respostas**: para **dúvidas operacionais comuns** ou **FAQs**.\n",
    "            - **politicas_e_procedimentos**: para questões sobre **políticas da empresa**, **garantia** ou **prazos de atendimento (SLA)**.\n",
    "            - **tickets**: para perguntas sobre o **status de um chamado**.\n",
    "\n",
    "            **Regras:**\n",
    "            - Responda apenas com a frase ou com a palavra-chave.\n",
    "            - Não adicione explicações, comentários ou qualquer outro texto.\n",
    "            - Não invente novas categorias.\"\"\"\n",
    "            )\n",
    "        ),\n",
    "        *chat_history,\n",
    "        HumanMessage(content=query),\n",
    "    ]\n",
    "\n",
    "    resposta = llm.invoke(mensagens)\n",
    "    resposta_limpa = resposta.content.strip().lower()\n",
    "\n",
    "    # Verifica se a resposta é uma das rotas ou se é uma resposta direta\n",
    "    if resposta_limpa in [\n",
    "        \"detalhe_tecnico\",\n",
    "        \"perguntas_e_respostas\",\n",
    "        \"politicas_e_procedimentos\",\n",
    "        \"tickets\",\n",
    "    ]:\n",
    "        state[\"route\"] = resposta_limpa\n",
    "    else:\n",
    "        state[\"answer\"] = resposta.content  # Salva a resposta direta na chave 'answer'\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba6c09",
   "metadata": {},
   "source": [
    "Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4efdbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3ff5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decidir o próximo passo\n",
    "def decide_action(state: State):\n",
    "    # Se a resposta já foi gerada pelo supervisor, encerra o fluxo.\n",
    "    if \"answer\" in state:\n",
    "        return \"end_workflow\"\n",
    "    else:\n",
    "        # Caso contrário, usa a rota para ir para o agente especialista.\n",
    "        return state[\"route\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a363011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_workflow():\n",
    "    workflow = StateGraph(State)\n",
    "\n",
    "    # Adicionar os nos\n",
    "    workflow.add_node(\"supervisor_node\", supervisor)\n",
    "    workflow.add_node(\"detalhe_tecnico_node\", agent_detalhe_tecnico)\n",
    "    workflow.add_node(\"perguntas_e_respostas_node\", agent_perguntas_e_respostas)\n",
    "    workflow.add_node(\"politicas_e_procedimentos_node\", agent_politicas_e_procedimentos)\n",
    "    workflow.add_node(\"tickets_node\", agent_tickets)\n",
    "\n",
    "    # Adicione um nó de saída para a resposta direta\n",
    "    workflow.add_node(\"end_workflow\", lambda x: x)\n",
    "\n",
    "    # Definir o nó inicial\n",
    "    workflow.add_edge(START, \"supervisor_node\")\n",
    "\n",
    "    # Adicione o roteamento condicional\n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor_node\",\n",
    "        decide_action,\n",
    "        {\n",
    "            \"detalhe_tecnico\": \"detalhe_tecnico_node\",\n",
    "            \"perguntas_e_respostas\": \"perguntas_e_respostas_node\",\n",
    "            \"politicas_e_procedimentos\": \"politicas_e_procedimentos_node\",\n",
    "            \"tickets\": \"tickets_node\",\n",
    "            \"end_workflow\": END,  # Termina o fluxo se a resposta já foi gerada pelo supervisor\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Defina as saídas dos agentes especialistas\n",
    "    workflow.add_edge(\"detalhe_tecnico_node\", END)\n",
    "    workflow.add_edge(\"perguntas_e_respostas_node\", END)\n",
    "    workflow.add_edge(\"politicas_e_procedimentos_node\", END)\n",
    "    workflow.add_edge(\"tickets_node\", END)\n",
    "\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c231c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = build_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6407b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistente-ai-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
